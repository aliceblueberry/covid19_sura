{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import GraphConv,EdgeConditionedConv\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flight_network import A, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(y)\n",
    "N = A.shape[0]\n",
    "F = X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = GraphConv.preprocess(A).astype('f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_8 (GraphConv)        (None, 51)           255         input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_9 (GraphConv)        (None, 51)           2652        graph_conv_8[0][0]               \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 51)           0           graph_conv_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_10 (GraphConv)       (None, 51)           2652        dropout[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            52          graph_conv_10[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,611\n",
      "Trainable params: 5,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "X_in = Input(shape=(F, ))\n",
    "A_in = Input((N, ), sparse=True)\n",
    "\n",
    "X_1 = GraphConv(51, 'relu')([X_in, A_in])\n",
    "X_2 = GraphConv(51, 'relu')([X_1, A_in])\n",
    "X_3 = GraphConv(51, 'relu')([X_2, A_in])\n",
    "output = Dense(1)(X_3)\n",
    "model = Model(inputs=[X_in, A_in], outputs=output)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mse','mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.astype('f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51 samples\n",
      "Epoch 1/200\n",
      "51/51 [==============================] - 0s 230us/sample - loss: 92168.8047 - mse: 92168.8047 - mae: 210.5596\n",
      "Epoch 2/200\n",
      "51/51 [==============================] - 0s 207us/sample - loss: 92315.2578 - mse: 92315.2578 - mae: 215.5108\n",
      "Epoch 3/200\n",
      "51/51 [==============================] - 0s 297us/sample - loss: 92194.5469 - mse: 92194.5469 - mae: 208.8393\n",
      "Epoch 4/200\n",
      "51/51 [==============================] - 0s 306us/sample - loss: 91856.8594 - mse: 91856.8594 - mae: 191.3450\n",
      "Epoch 5/200\n",
      "51/51 [==============================] - 0s 285us/sample - loss: 92081.1016 - mse: 92081.1016 - mae: 195.3479\n",
      "Epoch 6/200\n",
      "51/51 [==============================] - 0s 291us/sample - loss: 92394.3438 - mse: 92394.3438 - mae: 199.8333\n",
      "Epoch 7/200\n",
      "51/51 [==============================] - 0s 301us/sample - loss: 92366.4766 - mse: 92366.4766 - mae: 209.0378\n",
      "Epoch 8/200\n",
      "51/51 [==============================] - 0s 273us/sample - loss: 91835.1484 - mse: 91835.1484 - mae: 200.0792\n",
      "Epoch 9/200\n",
      "51/51 [==============================] - 0s 301us/sample - loss: 92165.7266 - mse: 92165.7266 - mae: 205.1957\n",
      "Epoch 10/200\n",
      "51/51 [==============================] - 0s 279us/sample - loss: 92132.0469 - mse: 92132.0469 - mae: 202.3208\n",
      "Epoch 11/200\n",
      "51/51 [==============================] - 0s 282us/sample - loss: 92812.5469 - mse: 92812.5469 - mae: 202.9648\n",
      "Epoch 12/200\n",
      "51/51 [==============================] - 0s 333us/sample - loss: 92769.2656 - mse: 92769.2656 - mae: 197.9127\n",
      "Epoch 13/200\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 92536.3438 - mse: 92536.3438 - mae: 192.0993\n",
      "Epoch 14/200\n",
      "51/51 [==============================] - 0s 503us/sample - loss: 92342.1641 - mse: 92342.1641 - mae: 195.2753\n",
      "Epoch 15/200\n",
      "51/51 [==============================] - 0s 415us/sample - loss: 91631.8359 - mse: 91631.8359 - mae: 198.1872\n",
      "Epoch 16/200\n",
      "51/51 [==============================] - 0s 374us/sample - loss: 92970.6562 - mse: 92970.6562 - mae: 205.1249\n",
      "Epoch 17/200\n",
      "51/51 [==============================] - 0s 326us/sample - loss: 92722.1172 - mse: 92722.1172 - mae: 210.7033\n",
      "Epoch 18/200\n",
      "51/51 [==============================] - 0s 355us/sample - loss: 92466.7266 - mse: 92466.7266 - mae: 214.0247\n",
      "Epoch 19/200\n",
      "51/51 [==============================] - 0s 465us/sample - loss: 91644.5312 - mse: 91644.5312 - mae: 198.7246\n",
      "Epoch 20/200\n",
      "51/51 [==============================] - 0s 346us/sample - loss: 93154.1953 - mse: 93154.1953 - mae: 211.4081\n",
      "Epoch 21/200\n",
      "51/51 [==============================] - 0s 286us/sample - loss: 92048.8828 - mse: 92048.8828 - mae: 204.6778\n",
      "Epoch 22/200\n",
      "51/51 [==============================] - 0s 233us/sample - loss: 92382.5000 - mse: 92382.5000 - mae: 207.2731\n",
      "Epoch 23/200\n",
      "51/51 [==============================] - 0s 206us/sample - loss: 91923.3828 - mse: 91923.3828 - mae: 198.5581\n",
      "Epoch 24/200\n",
      "51/51 [==============================] - 0s 271us/sample - loss: 92146.7422 - mse: 92146.7422 - mae: 199.8913\n",
      "Epoch 25/200\n",
      "51/51 [==============================] - 0s 325us/sample - loss: 92302.5078 - mse: 92302.5078 - mae: 194.6079\n",
      "Epoch 26/200\n",
      "51/51 [==============================] - 0s 307us/sample - loss: 92927.4766 - mse: 92927.4766 - mae: 187.4387\n",
      "Epoch 27/200\n",
      "51/51 [==============================] - 0s 316us/sample - loss: 93172.8438 - mse: 93172.8438 - mae: 197.6993\n",
      "Epoch 28/200\n",
      "51/51 [==============================] - 0s 329us/sample - loss: 91466.1562 - mse: 91466.1562 - mae: 198.4118\n",
      "Epoch 29/200\n",
      "51/51 [==============================] - 0s 345us/sample - loss: 90701.4688 - mse: 90701.4688 - mae: 199.5547\n",
      "Epoch 30/200\n",
      "51/51 [==============================] - 0s 448us/sample - loss: 92773.1562 - mse: 92773.1562 - mae: 210.3365\n",
      "Epoch 31/200\n",
      "51/51 [==============================] - 0s 376us/sample - loss: 91937.8359 - mse: 91937.8359 - mae: 207.7357\n",
      "Epoch 32/200\n",
      "51/51 [==============================] - 0s 361us/sample - loss: 92708.0625 - mse: 92708.0625 - mae: 200.8127\n",
      "Epoch 33/200\n",
      "51/51 [==============================] - 0s 340us/sample - loss: 93232.7344 - mse: 93232.7344 - mae: 208.1689\n",
      "Epoch 34/200\n",
      "51/51 [==============================] - 0s 336us/sample - loss: 92366.8516 - mse: 92366.8516 - mae: 201.8098\n",
      "Epoch 35/200\n",
      "51/51 [==============================] - 0s 319us/sample - loss: 91609.0625 - mse: 91609.0625 - mae: 209.4144\n",
      "Epoch 36/200\n",
      "51/51 [==============================] - 0s 314us/sample - loss: 93530.1172 - mse: 93530.1172 - mae: 192.0854\n",
      "Epoch 37/200\n",
      "51/51 [==============================] - 0s 328us/sample - loss: 92068.4766 - mse: 92068.4766 - mae: 199.1810\n",
      "Epoch 38/200\n",
      "51/51 [==============================] - 0s 317us/sample - loss: 92582.1094 - mse: 92582.1094 - mae: 202.0846\n",
      "Epoch 39/200\n",
      "51/51 [==============================] - 0s 324us/sample - loss: 92033.5312 - mse: 92033.5312 - mae: 199.0392\n",
      "Epoch 40/200\n",
      "51/51 [==============================] - 0s 323us/sample - loss: 93322.1406 - mse: 93322.1406 - mae: 192.5036\n",
      "Epoch 41/200\n",
      "51/51 [==============================] - 0s 329us/sample - loss: 91562.2031 - mse: 91562.2031 - mae: 198.9357\n",
      "Epoch 42/200\n",
      "51/51 [==============================] - 0s 332us/sample - loss: 93467.4297 - mse: 93467.4297 - mae: 215.3361\n",
      "Epoch 43/200\n",
      "51/51 [==============================] - 0s 270us/sample - loss: 92591.1641 - mse: 92591.1641 - mae: 215.6984\n",
      "Epoch 44/200\n",
      "51/51 [==============================] - 0s 246us/sample - loss: 91789.2344 - mse: 91789.2344 - mae: 202.0716\n",
      "Epoch 45/200\n",
      "51/51 [==============================] - 0s 292us/sample - loss: 92016.6797 - mse: 92016.6797 - mae: 191.1547\n",
      "Epoch 46/200\n",
      "51/51 [==============================] - 0s 288us/sample - loss: 92890.8203 - mse: 92890.8203 - mae: 189.9274\n",
      "Epoch 47/200\n",
      "51/51 [==============================] - 0s 277us/sample - loss: 91745.1953 - mse: 91745.1953 - mae: 194.0611\n",
      "Epoch 48/200\n",
      "51/51 [==============================] - 0s 340us/sample - loss: 93077.3203 - mse: 93077.3203 - mae: 208.5954\n",
      "Epoch 49/200\n",
      "51/51 [==============================] - 0s 326us/sample - loss: 92657.0391 - mse: 92657.0391 - mae: 199.9196\n",
      "Epoch 50/200\n",
      "51/51 [==============================] - 0s 319us/sample - loss: 91674.8750 - mse: 91674.8750 - mae: 205.9347\n",
      "Epoch 51/200\n",
      "51/51 [==============================] - 0s 341us/sample - loss: 91773.4219 - mse: 91773.4219 - mae: 197.5966\n",
      "Epoch 52/200\n",
      "51/51 [==============================] - 0s 318us/sample - loss: 92061.5469 - mse: 92061.5469 - mae: 207.9598\n",
      "Epoch 53/200\n",
      "51/51 [==============================] - 0s 466us/sample - loss: 92367.4922 - mse: 92367.4922 - mae: 196.3600\n",
      "Epoch 54/200\n",
      "51/51 [==============================] - 0s 284us/sample - loss: 91794.8984 - mse: 91794.8984 - mae: 201.6802\n",
      "Epoch 55/200\n",
      "51/51 [==============================] - 0s 573us/sample - loss: 91537.8906 - mse: 91537.8906 - mae: 194.4544\n",
      "Epoch 56/200\n",
      "51/51 [==============================] - 0s 294us/sample - loss: 92813.5391 - mse: 92813.5391 - mae: 204.8434\n",
      "Epoch 57/200\n",
      "51/51 [==============================] - 0s 344us/sample - loss: 91927.6562 - mse: 91927.6562 - mae: 203.6918\n",
      "Epoch 58/200\n",
      "51/51 [==============================] - 0s 241us/sample - loss: 90492.0391 - mse: 90492.0391 - mae: 199.9942\n",
      "Epoch 59/200\n",
      "51/51 [==============================] - 0s 421us/sample - loss: 91538.6641 - mse: 91538.6641 - mae: 200.2226\n",
      "Epoch 60/200\n",
      "51/51 [==============================] - 0s 244us/sample - loss: 92529.7188 - mse: 92529.7188 - mae: 210.9254\n",
      "Epoch 61/200\n",
      "51/51 [==============================] - 0s 323us/sample - loss: 91662.1172 - mse: 91662.1172 - mae: 196.7465\n",
      "Epoch 62/200\n",
      "51/51 [==============================] - 0s 259us/sample - loss: 91688.6953 - mse: 91688.6953 - mae: 209.6406\n",
      "Epoch 63/200\n",
      "51/51 [==============================] - 0s 267us/sample - loss: 91905.3516 - mse: 91905.3516 - mae: 197.1559\n",
      "Epoch 64/200\n",
      "51/51 [==============================] - 0s 233us/sample - loss: 94252.1484 - mse: 94252.1484 - mae: 207.7258\n",
      "Epoch 65/200\n",
      "51/51 [==============================] - 0s 240us/sample - loss: 92892.4766 - mse: 92892.4766 - mae: 209.3136\n",
      "Epoch 66/200\n",
      "51/51 [==============================] - 0s 218us/sample - loss: 91819.6875 - mse: 91819.6875 - mae: 190.7233\n",
      "Epoch 67/200\n",
      "51/51 [==============================] - 0s 218us/sample - loss: 91353.6641 - mse: 91353.6641 - mae: 194.4143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "51/51 [==============================] - 0s 219us/sample - loss: 92255.8438 - mse: 92255.8438 - mae: 194.1943\n",
      "Epoch 69/200\n",
      "51/51 [==============================] - 0s 240us/sample - loss: 92824.4297 - mse: 92824.4297 - mae: 210.4714\n",
      "Epoch 70/200\n",
      "51/51 [==============================] - 0s 258us/sample - loss: 94375.1875 - mse: 94375.1875 - mae: 207.8675\n",
      "Epoch 71/200\n",
      "51/51 [==============================] - 0s 223us/sample - loss: 91497.7344 - mse: 91497.7344 - mae: 193.5609\n",
      "Epoch 72/200\n",
      "51/51 [==============================] - 0s 226us/sample - loss: 93004.7969 - mse: 93004.7969 - mae: 188.5986\n",
      "Epoch 73/200\n",
      "51/51 [==============================] - 0s 200us/sample - loss: 94210.3906 - mse: 94210.3906 - mae: 186.0472\n",
      "Epoch 74/200\n",
      "51/51 [==============================] - 0s 202us/sample - loss: 92140.5312 - mse: 92140.5312 - mae: 188.9839\n",
      "Epoch 75/200\n",
      "51/51 [==============================] - 0s 207us/sample - loss: 91135.6094 - mse: 91135.6094 - mae: 197.0690\n",
      "Epoch 76/200\n",
      "51/51 [==============================] - 0s 368us/sample - loss: 90800.4922 - mse: 90800.4922 - mae: 206.9428\n",
      "Epoch 77/200\n",
      "51/51 [==============================] - 0s 248us/sample - loss: 92638.2656 - mse: 92638.2656 - mae: 208.4107\n",
      "Epoch 78/200\n",
      "51/51 [==============================] - 0s 273us/sample - loss: 92795.4688 - mse: 92795.4688 - mae: 211.8494\n",
      "Epoch 79/200\n",
      "51/51 [==============================] - 0s 268us/sample - loss: 92153.6484 - mse: 92153.6484 - mae: 206.3130\n",
      "Epoch 80/200\n",
      "51/51 [==============================] - 0s 254us/sample - loss: 93781.5391 - mse: 93781.5391 - mae: 219.0311\n",
      "Epoch 81/200\n",
      "51/51 [==============================] - 0s 221us/sample - loss: 92285.4609 - mse: 92285.4609 - mae: 195.2454\n",
      "Epoch 82/200\n",
      "51/51 [==============================] - 0s 246us/sample - loss: 92131.4219 - mse: 92131.4219 - mae: 196.0457\n",
      "Epoch 83/200\n",
      "51/51 [==============================] - 0s 338us/sample - loss: 91281.6094 - mse: 91281.6094 - mae: 197.6375\n",
      "Epoch 84/200\n",
      "51/51 [==============================] - 0s 308us/sample - loss: 93320.8047 - mse: 93320.8047 - mae: 192.4552\n",
      "Epoch 85/200\n",
      "51/51 [==============================] - 0s 312us/sample - loss: 92064.3984 - mse: 92064.3984 - mae: 197.6528\n",
      "Epoch 86/200\n",
      "51/51 [==============================] - 0s 356us/sample - loss: 92367.2734 - mse: 92367.2734 - mae: 200.6626\n",
      "Epoch 87/200\n",
      "51/51 [==============================] - 0s 250us/sample - loss: 92061.5781 - mse: 92061.5781 - mae: 195.5870\n",
      "Epoch 88/200\n",
      "51/51 [==============================] - 0s 358us/sample - loss: 93081.3750 - mse: 93081.3750 - mae: 211.7881\n",
      "Epoch 89/200\n",
      "51/51 [==============================] - 0s 264us/sample - loss: 91682.6172 - mse: 91682.6172 - mae: 202.8803\n",
      "Epoch 90/200\n",
      "51/51 [==============================] - 0s 356us/sample - loss: 92757.1406 - mse: 92757.1406 - mae: 201.2565\n",
      "Epoch 91/200\n",
      "51/51 [==============================] - 0s 236us/sample - loss: 92270.6250 - mse: 92270.6250 - mae: 196.6449\n",
      "Epoch 92/200\n",
      "51/51 [==============================] - 0s 299us/sample - loss: 92312.4922 - mse: 92312.4922 - mae: 209.7464\n",
      "Epoch 93/200\n",
      "51/51 [==============================] - 0s 280us/sample - loss: 91637.8047 - mse: 91637.8047 - mae: 200.0910\n",
      "Epoch 94/200\n",
      "51/51 [==============================] - 0s 336us/sample - loss: 91737.5625 - mse: 91737.5625 - mae: 196.7486\n",
      "Epoch 95/200\n",
      "51/51 [==============================] - 0s 279us/sample - loss: 93084.5625 - mse: 93084.5625 - mae: 192.6859\n",
      "Epoch 96/200\n",
      "51/51 [==============================] - 0s 344us/sample - loss: 91224.8594 - mse: 91224.8594 - mae: 201.4236\n",
      "Epoch 97/200\n",
      "51/51 [==============================] - 0s 327us/sample - loss: 91613.2656 - mse: 91613.2656 - mae: 194.0400\n",
      "Epoch 98/200\n",
      "51/51 [==============================] - 0s 311us/sample - loss: 92052.8984 - mse: 92052.8984 - mae: 207.8057\n",
      "Epoch 99/200\n",
      "51/51 [==============================] - 0s 250us/sample - loss: 92499.1250 - mse: 92499.1250 - mae: 202.4296\n",
      "Epoch 100/200\n",
      "51/51 [==============================] - 0s 229us/sample - loss: 92451.7734 - mse: 92451.7734 - mae: 204.8970\n",
      "Epoch 101/200\n",
      "51/51 [==============================] - 0s 255us/sample - loss: 92897.1250 - mse: 92897.1250 - mae: 195.1149\n",
      "Epoch 102/200\n",
      "51/51 [==============================] - 0s 229us/sample - loss: 91868.5859 - mse: 91868.5859 - mae: 195.4156\n",
      "Epoch 103/200\n",
      "51/51 [==============================] - 0s 260us/sample - loss: 92539.0312 - mse: 92539.0312 - mae: 200.0541\n",
      "Epoch 104/200\n",
      "51/51 [==============================] - 0s 266us/sample - loss: 92217.0859 - mse: 92217.0859 - mae: 210.6280\n",
      "Epoch 105/200\n",
      "51/51 [==============================] - 0s 669us/sample - loss: 93624.6641 - mse: 93624.6641 - mae: 216.3827\n",
      "Epoch 106/200\n",
      "51/51 [==============================] - 0s 597us/sample - loss: 91692.2031 - mse: 91692.2031 - mae: 199.9892\n",
      "Epoch 107/200\n",
      "51/51 [==============================] - 0s 437us/sample - loss: 91679.8125 - mse: 91679.8125 - mae: 198.1002\n",
      "Epoch 108/200\n",
      "51/51 [==============================] - 0s 550us/sample - loss: 91643.8359 - mse: 91643.8359 - mae: 203.6021\n",
      "Epoch 109/200\n",
      "51/51 [==============================] - 0s 341us/sample - loss: 91666.8203 - mse: 91666.8203 - mae: 196.5771\n",
      "Epoch 110/200\n",
      "51/51 [==============================] - 0s 278us/sample - loss: 91903.8594 - mse: 91903.8594 - mae: 194.7679\n",
      "Epoch 111/200\n",
      "51/51 [==============================] - 0s 274us/sample - loss: 92523.8125 - mse: 92523.8125 - mae: 200.3139\n",
      "Epoch 112/200\n",
      "51/51 [==============================] - 0s 382us/sample - loss: 91037.7031 - mse: 91037.7031 - mae: 197.4975\n",
      "Epoch 113/200\n",
      "51/51 [==============================] - 0s 328us/sample - loss: 92659.7266 - mse: 92659.7266 - mae: 205.8739\n",
      "Epoch 114/200\n",
      "51/51 [==============================] - 0s 292us/sample - loss: 92649.0078 - mse: 92649.0078 - mae: 195.9295\n",
      "Epoch 115/200\n",
      "51/51 [==============================] - 0s 298us/sample - loss: 91368.8828 - mse: 91368.8828 - mae: 202.1307\n",
      "Epoch 116/200\n",
      "51/51 [==============================] - 0s 270us/sample - loss: 91785.4375 - mse: 91785.4375 - mae: 201.8905\n",
      "Epoch 117/200\n",
      "51/51 [==============================] - 0s 318us/sample - loss: 93221.1562 - mse: 93221.1562 - mae: 209.9042\n",
      "Epoch 118/200\n",
      "51/51 [==============================] - 0s 257us/sample - loss: 91661.5312 - mse: 91661.5312 - mae: 194.6107\n",
      "Epoch 119/200\n",
      "51/51 [==============================] - 0s 194us/sample - loss: 92796.9141 - mse: 92796.9141 - mae: 200.0987\n",
      "Epoch 120/200\n",
      "51/51 [==============================] - 0s 251us/sample - loss: 92092.1484 - mse: 92092.1484 - mae: 195.6749\n",
      "Epoch 121/200\n",
      "51/51 [==============================] - 0s 311us/sample - loss: 91594.0312 - mse: 91594.0312 - mae: 199.1850\n",
      "Epoch 122/200\n",
      "51/51 [==============================] - 0s 265us/sample - loss: 91226.7578 - mse: 91226.7578 - mae: 201.7043\n",
      "Epoch 123/200\n",
      "51/51 [==============================] - 0s 239us/sample - loss: 92505.9766 - mse: 92505.9766 - mae: 209.2507\n",
      "Epoch 124/200\n",
      "51/51 [==============================] - 0s 343us/sample - loss: 92671.1875 - mse: 92671.1875 - mae: 206.1221\n",
      "Epoch 125/200\n",
      "51/51 [==============================] - 0s 263us/sample - loss: 92630.6406 - mse: 92630.6406 - mae: 198.3111\n",
      "Epoch 126/200\n",
      "51/51 [==============================] - 0s 319us/sample - loss: 91376.0312 - mse: 91376.0312 - mae: 192.7997\n",
      "Epoch 127/200\n",
      "51/51 [==============================] - 0s 255us/sample - loss: 91394.5703 - mse: 91394.5703 - mae: 202.4464\n",
      "Epoch 128/200\n",
      "51/51 [==============================] - 0s 289us/sample - loss: 92638.2578 - mse: 92638.2578 - mae: 194.2209\n",
      "Epoch 129/200\n",
      "51/51 [==============================] - 0s 318us/sample - loss: 92480.9375 - mse: 92480.9375 - mae: 205.2178\n",
      "Epoch 130/200\n",
      "51/51 [==============================] - 0s 328us/sample - loss: 92076.2578 - mse: 92076.2578 - mae: 195.5624\n",
      "Epoch 131/200\n",
      "51/51 [==============================] - 0s 304us/sample - loss: 91905.1875 - mse: 91905.1875 - mae: 199.7726\n",
      "Epoch 132/200\n",
      "51/51 [==============================] - 0s 299us/sample - loss: 91721.1562 - mse: 91721.1562 - mae: 202.3470\n",
      "Epoch 133/200\n",
      "51/51 [==============================] - 0s 337us/sample - loss: 92378.4297 - mse: 92378.4297 - mae: 207.8600\n",
      "Epoch 134/200\n",
      "51/51 [==============================] - 0s 445us/sample - loss: 91615.5078 - mse: 91615.5078 - mae: 198.6366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      "51/51 [==============================] - 0s 257us/sample - loss: 91821.1797 - mse: 91821.1797 - mae: 200.2253\n",
      "Epoch 136/200\n",
      "51/51 [==============================] - 0s 329us/sample - loss: 92292.4922 - mse: 92292.4922 - mae: 211.7128\n",
      "Epoch 137/200\n",
      "51/51 [==============================] - 0s 383us/sample - loss: 91381.9141 - mse: 91381.9141 - mae: 197.1742\n",
      "Epoch 138/200\n",
      "51/51 [==============================] - 0s 295us/sample - loss: 92172.9531 - mse: 92172.9531 - mae: 195.5396\n",
      "Epoch 139/200\n",
      "51/51 [==============================] - 0s 447us/sample - loss: 92609.3516 - mse: 92609.3516 - mae: 203.5640\n",
      "Epoch 140/200\n",
      "51/51 [==============================] - 0s 298us/sample - loss: 92286.8125 - mse: 92286.8125 - mae: 210.3860\n",
      "Epoch 141/200\n",
      "51/51 [==============================] - 0s 410us/sample - loss: 92521.9531 - mse: 92521.9531 - mae: 192.9748\n",
      "Epoch 142/200\n",
      "51/51 [==============================] - 0s 365us/sample - loss: 91708.5234 - mse: 91708.5234 - mae: 194.9654\n",
      "Epoch 143/200\n",
      "51/51 [==============================] - 0s 330us/sample - loss: 93517.7266 - mse: 93517.7266 - mae: 193.8206\n",
      "Epoch 144/200\n",
      "51/51 [==============================] - 0s 333us/sample - loss: 93004.7656 - mse: 93004.7656 - mae: 189.7456\n",
      "Epoch 145/200\n",
      "51/51 [==============================] - 0s 312us/sample - loss: 92363.0234 - mse: 92363.0234 - mae: 198.8599\n",
      "Epoch 146/200\n",
      "51/51 [==============================] - 0s 348us/sample - loss: 92078.6172 - mse: 92078.6172 - mae: 211.0669\n",
      "Epoch 147/200\n",
      "51/51 [==============================] - 0s 367us/sample - loss: 92397.7188 - mse: 92397.7188 - mae: 205.4870\n",
      "Epoch 148/200\n",
      "51/51 [==============================] - 0s 346us/sample - loss: 91317.9688 - mse: 91317.9688 - mae: 203.5917\n",
      "Epoch 149/200\n",
      "51/51 [==============================] - 0s 316us/sample - loss: 92090.4219 - mse: 92090.4219 - mae: 208.6225\n",
      "Epoch 150/200\n",
      "51/51 [==============================] - 0s 261us/sample - loss: 92868.5234 - mse: 92868.5234 - mae: 193.8033\n",
      "Epoch 151/200\n",
      "51/51 [==============================] - 0s 331us/sample - loss: 92074.1641 - mse: 92074.1641 - mae: 208.8078\n",
      "Epoch 152/200\n",
      "51/51 [==============================] - 0s 322us/sample - loss: 91649.3203 - mse: 91649.3203 - mae: 198.8105\n",
      "Epoch 153/200\n",
      "51/51 [==============================] - 0s 338us/sample - loss: 91287.2188 - mse: 91287.2188 - mae: 203.3713\n",
      "Epoch 154/200\n",
      "51/51 [==============================] - 0s 328us/sample - loss: 92392.5469 - mse: 92392.5469 - mae: 201.9461\n",
      "Epoch 155/200\n",
      "51/51 [==============================] - 0s 279us/sample - loss: 93122.5312 - mse: 93122.5312 - mae: 192.5289\n",
      "Epoch 156/200\n",
      "51/51 [==============================] - 0s 332us/sample - loss: 93150.4141 - mse: 93150.4141 - mae: 195.6873\n",
      "Epoch 157/200\n",
      "51/51 [==============================] - 0s 340us/sample - loss: 92262.6875 - mse: 92262.6875 - mae: 189.8864\n",
      "Epoch 158/200\n",
      "51/51 [==============================] - 0s 336us/sample - loss: 92998.9297 - mse: 92998.9297 - mae: 194.0469\n",
      "Epoch 159/200\n",
      "51/51 [==============================] - 0s 396us/sample - loss: 92048.5625 - mse: 92048.5625 - mae: 202.3445\n",
      "Epoch 160/200\n",
      "51/51 [==============================] - 0s 324us/sample - loss: 92097.3594 - mse: 92097.3594 - mae: 207.7922\n",
      "Epoch 161/200\n",
      "51/51 [==============================] - 0s 275us/sample - loss: 91606.2656 - mse: 91606.2656 - mae: 203.1473\n",
      "Epoch 162/200\n",
      "51/51 [==============================] - 0s 343us/sample - loss: 92155.0234 - mse: 92155.0234 - mae: 201.0580\n",
      "Epoch 163/200\n",
      "51/51 [==============================] - 0s 326us/sample - loss: 93296.7656 - mse: 93296.7656 - mae: 212.7114\n",
      "Epoch 164/200\n",
      "51/51 [==============================] - 0s 295us/sample - loss: 91988.4922 - mse: 91988.4922 - mae: 211.3392\n",
      "Epoch 165/200\n",
      "51/51 [==============================] - 0s 280us/sample - loss: 92713.8359 - mse: 92713.8359 - mae: 204.3100\n",
      "Epoch 166/200\n",
      "51/51 [==============================] - 0s 314us/sample - loss: 92203.1875 - mse: 92203.1875 - mae: 195.7032\n",
      "Epoch 167/200\n",
      "51/51 [==============================] - 0s 288us/sample - loss: 92358.3750 - mse: 92358.3750 - mae: 192.6221\n",
      "Epoch 168/200\n",
      "51/51 [==============================] - 0s 323us/sample - loss: 92035.5000 - mse: 92035.5000 - mae: 203.0857\n",
      "Epoch 169/200\n",
      "51/51 [==============================] - 0s 326us/sample - loss: 92558.2969 - mse: 92558.2969 - mae: 199.0735\n",
      "Epoch 170/200\n",
      "51/51 [==============================] - 0s 206us/sample - loss: 92509.2344 - mse: 92509.2344 - mae: 198.9328\n",
      "Epoch 171/200\n",
      "51/51 [==============================] - 0s 302us/sample - loss: 91625.7578 - mse: 91625.7578 - mae: 198.4251\n",
      "Epoch 172/200\n",
      "51/51 [==============================] - 0s 259us/sample - loss: 92653.7578 - mse: 92653.7578 - mae: 197.1405\n",
      "Epoch 173/200\n",
      "51/51 [==============================] - 0s 308us/sample - loss: 92146.1484 - mse: 92146.1484 - mae: 205.2351\n",
      "Epoch 174/200\n",
      "51/51 [==============================] - 0s 257us/sample - loss: 91965.1250 - mse: 91965.1250 - mae: 185.6758\n",
      "Epoch 175/200\n",
      "51/51 [==============================] - 0s 355us/sample - loss: 91834.1953 - mse: 91834.1953 - mae: 201.5848\n",
      "Epoch 176/200\n",
      "51/51 [==============================] - 0s 363us/sample - loss: 91027.7422 - mse: 91027.7422 - mae: 205.1046\n",
      "Epoch 177/200\n",
      "51/51 [==============================] - 0s 292us/sample - loss: 91875.8203 - mse: 91875.8203 - mae: 204.5964\n",
      "Epoch 178/200\n",
      "51/51 [==============================] - 0s 323us/sample - loss: 91593.4766 - mse: 91593.4766 - mae: 203.2457\n",
      "Epoch 179/200\n",
      "51/51 [==============================] - 0s 456us/sample - loss: 92050.6641 - mse: 92050.6641 - mae: 201.9409\n",
      "Epoch 180/200\n",
      "51/51 [==============================] - 0s 311us/sample - loss: 92679.7656 - mse: 92679.7656 - mae: 212.0568\n",
      "Epoch 181/200\n",
      "51/51 [==============================] - 0s 341us/sample - loss: 91331.8984 - mse: 91331.8984 - mae: 193.1243\n",
      "Epoch 182/200\n",
      "51/51 [==============================] - 0s 349us/sample - loss: 92115.0000 - mse: 92115.0000 - mae: 202.8611\n",
      "Epoch 183/200\n",
      "51/51 [==============================] - 0s 283us/sample - loss: 90492.7188 - mse: 90492.7188 - mae: 200.8444\n",
      "Epoch 184/200\n",
      "51/51 [==============================] - 0s 280us/sample - loss: 92802.4766 - mse: 92802.4766 - mae: 197.6795\n",
      "Epoch 185/200\n",
      "51/51 [==============================] - 0s 292us/sample - loss: 92359.3125 - mse: 92359.3125 - mae: 193.1941\n",
      "Epoch 186/200\n",
      "51/51 [==============================] - 0s 373us/sample - loss: 91438.9688 - mse: 91438.9688 - mae: 199.0130\n",
      "Epoch 187/200\n",
      "51/51 [==============================] - 0s 280us/sample - loss: 91029.8047 - mse: 91029.8047 - mae: 202.9333\n",
      "Epoch 188/200\n",
      "51/51 [==============================] - 0s 293us/sample - loss: 92662.2031 - mse: 92662.2031 - mae: 188.0284\n",
      "Epoch 189/200\n",
      "51/51 [==============================] - 0s 386us/sample - loss: 92634.6094 - mse: 92634.6094 - mae: 198.9061\n",
      "Epoch 190/200\n",
      "51/51 [==============================] - 0s 291us/sample - loss: 93023.9297 - mse: 93023.9297 - mae: 203.0605\n",
      "Epoch 191/200\n",
      "51/51 [==============================] - 0s 323us/sample - loss: 92768.8594 - mse: 92768.8594 - mae: 208.1080\n",
      "Epoch 192/200\n",
      "51/51 [==============================] - 0s 319us/sample - loss: 91337.3359 - mse: 91337.3359 - mae: 199.4846\n",
      "Epoch 193/200\n",
      "51/51 [==============================] - 0s 329us/sample - loss: 91609.0703 - mse: 91609.0703 - mae: 206.3020\n",
      "Epoch 194/200\n",
      "51/51 [==============================] - 0s 311us/sample - loss: 91883.8906 - mse: 91883.8906 - mae: 199.7542\n",
      "Epoch 195/200\n",
      "51/51 [==============================] - 0s 333us/sample - loss: 92683.6172 - mse: 92683.6172 - mae: 202.6651\n",
      "Epoch 196/200\n",
      "51/51 [==============================] - 0s 318us/sample - loss: 91993.0469 - mse: 91993.0469 - mae: 196.4835\n",
      "Epoch 197/200\n",
      "51/51 [==============================] - 0s 384us/sample - loss: 91765.6172 - mse: 91765.6172 - mae: 204.4741\n",
      "Epoch 198/200\n",
      "51/51 [==============================] - 0s 351us/sample - loss: 92659.1641 - mse: 92659.1641 - mae: 209.1514\n",
      "Epoch 199/200\n",
      "51/51 [==============================] - 0s 217us/sample - loss: 92787.7188 - mse: 92787.7188 - mae: 200.1198\n",
      "Epoch 200/200\n",
      "51/51 [==============================] - 0s 295us/sample - loss: 92002.2344 - mse: 92002.2344 - mae: 196.9075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b547b00>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, A], y,\n",
    "          batch_size = N, \n",
    "          epochs = 200,\n",
    "          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 82us/sample - loss: 92242.8047 - mse: 92242.8047 - mae: 202.1004\n",
      "Done.\n",
      "Test loss: 92242.8046875\n",
      "Test accuracy: 92242.8046875\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate([X, A],\n",
    "                              y,\n",
    "                              batch_size=N)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X,A],batch_size = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101132.03743757217\n"
     ]
    }
   ],
   "source": [
    "mse = np.mean((y - y_pred)**2)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  93.8794592    37.33342806   18.60469427 ...    1.53902301\n",
      "    80.02361539 -343.74786531]\n",
      " [ 156.31488401   99.76885286   81.04011907 ...   63.97444781\n",
      "   142.45904019 -281.31244051]\n",
      " [ 170.10005551  113.55402437   94.82529058 ...   77.75961932\n",
      "   156.2442117  -267.527269  ]\n",
      " ...\n",
      " [ 213.3338049   156.78777376  138.05903997 ...  120.99336871\n",
      "   199.47796109 -224.29351961]\n",
      " [ 106.28676206   49.74073092   31.01199712 ...   13.94632586\n",
      "    92.43091825 -331.34056246]\n",
      " [ 123.42239743   66.87636629   48.1476325  ...   31.08196124\n",
      "   109.56655362 -314.20492708]]\n"
     ]
    }
   ],
   "source": [
    "pred_error = y_pred-y\n",
    "print(pred_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Errors')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14ad10358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(pred_error, density=True, bins=30)\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
