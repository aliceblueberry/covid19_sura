{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.layers import GraphConv,EdgeConditionedConv\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flight_network import A, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(y)\n",
    "N = A.shape[0]\n",
    "F = X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = GraphConv.preprocess(A).astype('f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_20 (GraphConv)       (None, 51)           255         input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_21 (GraphConv)       (None, 51)           2652        graph_conv_20[0][0]              \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_22 (GraphConv)       (None, 51)           2652        graph_conv_21[0][0]              \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            52          graph_conv_22[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,611\n",
      "Trainable params: 5,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "X_in = Input(shape=(F, ))\n",
    "A_in = Input((N, ), sparse=True)\n",
    "\n",
    "X_1 = GraphConv(51, 'relu')([X_in, A_in])\n",
    "X_2 = GraphConv(51, 'relu')([X_1, A_in])\n",
    "X_3 = GraphConv(51, 'relu')([X_2, A_in])\n",
    "output = Dense(1)(X_3)\n",
    "model = Model(inputs=[X_in, A_in], outputs=output)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mse','mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.astype('f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51 samples\n",
      "Epoch 1/200\n",
      "51/51 [==============================] - 0s 196us/sample - loss: 92085.3125 - mse: 92085.3125 - mae: 201.8776\n",
      "Epoch 2/200\n",
      "51/51 [==============================] - 0s 295us/sample - loss: 92084.4766 - mse: 92084.4766 - mae: 201.6265\n",
      "Epoch 3/200\n",
      "51/51 [==============================] - 0s 335us/sample - loss: 92084.0234 - mse: 92084.0234 - mae: 201.4499\n",
      "Epoch 4/200\n",
      "51/51 [==============================] - 0s 310us/sample - loss: 92083.2031 - mse: 92083.2031 - mae: 201.6041\n",
      "Epoch 5/200\n",
      "51/51 [==============================] - 0s 301us/sample - loss: 92082.5859 - mse: 92082.5859 - mae: 201.7530\n",
      "Epoch 6/200\n",
      "51/51 [==============================] - 0s 305us/sample - loss: 92081.6406 - mse: 92081.6406 - mae: 201.6684\n",
      "Epoch 7/200\n",
      "51/51 [==============================] - 0s 269us/sample - loss: 92080.6875 - mse: 92080.6875 - mae: 201.4914\n",
      "Epoch 8/200\n",
      "51/51 [==============================] - 0s 290us/sample - loss: 92079.5859 - mse: 92079.5859 - mae: 201.5005\n",
      "Epoch 9/200\n",
      "51/51 [==============================] - 0s 310us/sample - loss: 92078.4297 - mse: 92078.4297 - mae: 201.6633\n",
      "Epoch 10/200\n",
      "51/51 [==============================] - 0s 302us/sample - loss: 92077.3125 - mse: 92077.3125 - mae: 201.7107\n",
      "Epoch 11/200\n",
      "51/51 [==============================] - 0s 300us/sample - loss: 92076.1250 - mse: 92076.1250 - mae: 201.6333\n",
      "Epoch 12/200\n",
      "51/51 [==============================] - 0s 267us/sample - loss: 92074.8359 - mse: 92074.8359 - mae: 201.5645\n",
      "Epoch 13/200\n",
      "51/51 [==============================] - 0s 313us/sample - loss: 92073.4531 - mse: 92073.4531 - mae: 201.6041\n",
      "Epoch 14/200\n",
      "51/51 [==============================] - 0s 376us/sample - loss: 92072.0391 - mse: 92072.0391 - mae: 201.6695\n",
      "Epoch 15/200\n",
      "51/51 [==============================] - 0s 297us/sample - loss: 92070.5312 - mse: 92070.5312 - mae: 201.5788\n",
      "Epoch 16/200\n",
      "51/51 [==============================] - 0s 248us/sample - loss: 92069.0000 - mse: 92069.0000 - mae: 201.4804\n",
      "Epoch 17/200\n",
      "51/51 [==============================] - 0s 321us/sample - loss: 92071.9609 - mse: 92071.9609 - mae: 201.6029\n",
      "Epoch 18/200\n",
      "51/51 [==============================] - 0s 453us/sample - loss: 92071.4297 - mse: 92071.4297 - mae: 201.6850\n",
      "Epoch 19/200\n",
      "51/51 [==============================] - 0s 395us/sample - loss: 92070.7344 - mse: 92070.7344 - mae: 201.5327\n",
      "Epoch 20/200\n",
      "51/51 [==============================] - 0s 581us/sample - loss: 92069.9688 - mse: 92069.9688 - mae: 201.6040\n",
      "Epoch 21/200\n",
      "51/51 [==============================] - 0s 482us/sample - loss: 92069.1875 - mse: 92069.1875 - mae: 201.6634\n",
      "Epoch 22/200\n",
      "51/51 [==============================] - 0s 355us/sample - loss: 92068.4219 - mse: 92068.4219 - mae: 201.5338\n",
      "Epoch 23/200\n",
      "51/51 [==============================] - 0s 280us/sample - loss: 92067.7188 - mse: 92067.7188 - mae: 201.5210\n",
      "Epoch 24/200\n",
      "51/51 [==============================] - 0s 226us/sample - loss: 92066.9531 - mse: 92066.9531 - mae: 201.6460\n",
      "Epoch 25/200\n",
      "51/51 [==============================] - 0s 308us/sample - loss: 92066.1250 - mse: 92066.1250 - mae: 201.5182\n",
      "Epoch 26/200\n",
      "51/51 [==============================] - 0s 310us/sample - loss: 92065.3438 - mse: 92065.3438 - mae: 201.5365\n",
      "Epoch 27/200\n",
      "51/51 [==============================] - 0s 226us/sample - loss: 92064.6406 - mse: 92064.6406 - mae: 201.7104\n",
      "Epoch 28/200\n",
      "51/51 [==============================] - 0s 320us/sample - loss: 92063.7734 - mse: 92063.7734 - mae: 201.4847\n",
      "Epoch 29/200\n",
      "51/51 [==============================] - 0s 410us/sample - loss: 92062.8828 - mse: 92062.8828 - mae: 201.5928\n",
      "Epoch 30/200\n",
      "51/51 [==============================] - 0s 282us/sample - loss: 92062.0859 - mse: 92062.0859 - mae: 201.5702\n",
      "Epoch 31/200\n",
      "51/51 [==============================] - 0s 353us/sample - loss: 92061.2656 - mse: 92061.2656 - mae: 201.4861\n",
      "Epoch 32/200\n",
      "51/51 [==============================] - 0s 395us/sample - loss: 92060.4297 - mse: 92060.4297 - mae: 201.6127\n",
      "Epoch 33/200\n",
      "51/51 [==============================] - 0s 426us/sample - loss: 92059.5781 - mse: 92059.5781 - mae: 201.5828\n",
      "Epoch 34/200\n",
      "51/51 [==============================] - 0s 401us/sample - loss: 92058.7266 - mse: 92058.7266 - mae: 201.4993\n",
      "Epoch 35/200\n",
      "51/51 [==============================] - 0s 319us/sample - loss: 92057.9219 - mse: 92057.9219 - mae: 201.6471\n",
      "Epoch 36/200\n",
      "51/51 [==============================] - 0s 296us/sample - loss: 92057.0859 - mse: 92057.0859 - mae: 201.4066\n",
      "Epoch 37/200\n",
      "51/51 [==============================] - 0s 287us/sample - loss: 92056.1953 - mse: 92056.1953 - mae: 201.6414\n",
      "Epoch 38/200\n",
      "51/51 [==============================] - 0s 376us/sample - loss: 92055.2812 - mse: 92055.2812 - mae: 201.4532\n",
      "Epoch 39/200\n",
      "51/51 [==============================] - 0s 321us/sample - loss: 92054.3906 - mse: 92054.3906 - mae: 201.6304\n",
      "Epoch 40/200\n",
      "51/51 [==============================] - 0s 319us/sample - loss: 92053.5859 - mse: 92053.5859 - mae: 201.4082\n",
      "Epoch 41/200\n",
      "51/51 [==============================] - 0s 386us/sample - loss: 92052.7188 - mse: 92052.7188 - mae: 201.7148\n",
      "Epoch 42/200\n",
      "51/51 [==============================] - 0s 364us/sample - loss: 92051.7656 - mse: 92051.7656 - mae: 201.3389\n",
      "Epoch 43/200\n",
      "51/51 [==============================] - 0s 365us/sample - loss: 92051.0625 - mse: 92051.0625 - mae: 201.7480\n",
      "Epoch 44/200\n",
      "51/51 [==============================] - 0s 312us/sample - loss: 92050.3047 - mse: 92050.3047 - mae: 201.2259\n",
      "Epoch 45/200\n",
      "51/51 [==============================] - 0s 256us/sample - loss: 92049.6094 - mse: 92049.6094 - mae: 201.8636\n",
      "Epoch 46/200\n",
      "51/51 [==============================] - 0s 325us/sample - loss: 92049.0391 - mse: 92049.0391 - mae: 201.0507\n",
      "Epoch 47/200\n",
      "51/51 [==============================] - 0s 340us/sample - loss: 92048.8906 - mse: 92048.8906 - mae: 202.1168\n",
      "Epoch 48/200\n",
      "51/51 [==============================] - 0s 332us/sample - loss: 92050.1875 - mse: 92050.1875 - mae: 200.6454\n",
      "Epoch 49/200\n",
      "51/51 [==============================] - 0s 256us/sample - loss: 92053.9219 - mse: 92053.9219 - mae: 202.8088\n",
      "Epoch 50/200\n",
      "51/51 [==============================] - 0s 272us/sample - loss: 92061.0781 - mse: 92061.0781 - mae: 199.7324\n",
      "Epoch 51/200\n",
      "51/51 [==============================] - 0s 348us/sample - loss: 92068.1797 - mse: 92068.1797 - mae: 203.6704\n",
      "Epoch 52/200\n",
      "51/51 [==============================] - 0s 356us/sample - loss: 92065.6016 - mse: 92065.6016 - mae: 199.4167\n",
      "Epoch 53/200\n",
      "51/51 [==============================] - 0s 327us/sample - loss: 92049.5469 - mse: 92049.5469 - mae: 202.7278\n",
      "Epoch 54/200\n",
      "51/51 [==============================] - 0s 380us/sample - loss: 92040.8359 - mse: 92040.8359 - mae: 201.5779\n",
      "Epoch 55/200\n",
      "51/51 [==============================] - 0s 222us/sample - loss: 92047.5391 - mse: 92047.5391 - mae: 200.3002\n",
      "Epoch 56/200\n",
      "51/51 [==============================] - 0s 445us/sample - loss: 92053.8438 - mse: 92053.8438 - mae: 203.1540\n",
      "Epoch 57/200\n",
      "51/51 [==============================] - 0s 432us/sample - loss: 92047.1797 - mse: 92047.1797 - mae: 200.1850\n",
      "Epoch 58/200\n",
      "51/51 [==============================] - 0s 350us/sample - loss: 92038.0000 - mse: 92038.0000 - mae: 201.7911\n",
      "Epoch 59/200\n",
      "51/51 [==============================] - 0s 301us/sample - loss: 92039.4609 - mse: 92039.4609 - mae: 202.1984\n",
      "Epoch 60/200\n",
      "51/51 [==============================] - 0s 370us/sample - loss: 92044.8750 - mse: 92044.8750 - mae: 200.1528\n",
      "Epoch 61/200\n",
      "51/51 [==============================] - 0s 399us/sample - loss: 92042.8516 - mse: 92042.8516 - mae: 202.6880\n",
      "Epoch 62/200\n",
      "51/51 [==============================] - 0s 329us/sample - loss: 92035.3984 - mse: 92035.3984 - mae: 200.9579\n",
      "Epoch 63/200\n",
      "51/51 [==============================] - 0s 512us/sample - loss: 92034.0859 - mse: 92034.0859 - mae: 201.0353\n",
      "Epoch 64/200\n",
      "51/51 [==============================] - 0s 263us/sample - loss: 92037.8906 - mse: 92037.8906 - mae: 202.4928\n",
      "Epoch 65/200\n",
      "51/51 [==============================] - 0s 401us/sample - loss: 92037.9375 - mse: 92037.9375 - mae: 200.3572\n",
      "Epoch 66/200\n",
      "51/51 [==============================] - 0s 271us/sample - loss: 92032.8047 - mse: 92032.8047 - mae: 202.1310\n",
      "Epoch 67/200\n",
      "51/51 [==============================] - 0s 327us/sample - loss: 92029.6875 - mse: 92029.6875 - mae: 201.4720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "51/51 [==============================] - 0s 323us/sample - loss: 92030.6250 - mse: 92030.6250 - mae: 200.8716\n",
      "Epoch 69/200\n",
      "51/51 [==============================] - 0s 353us/sample - loss: 92032.1797 - mse: 92032.1797 - mae: 202.3526\n",
      "Epoch 70/200\n",
      "51/51 [==============================] - 0s 377us/sample - loss: 92030.4297 - mse: 92030.4297 - mae: 200.6398\n",
      "Epoch 71/200\n",
      "51/51 [==============================] - 0s 375us/sample - loss: 92026.9297 - mse: 92026.9297 - mae: 201.8981\n",
      "Epoch 72/200\n",
      "51/51 [==============================] - 0s 290us/sample - loss: 92024.9766 - mse: 92024.9766 - mae: 201.5181\n",
      "Epoch 73/200\n",
      "51/51 [==============================] - 0s 229us/sample - loss: 92025.6562 - mse: 92025.6562 - mae: 200.8720\n",
      "Epoch 74/200\n",
      "51/51 [==============================] - 0s 223us/sample - loss: 92026.5000 - mse: 92026.5000 - mae: 202.2255\n",
      "Epoch 75/200\n",
      "51/51 [==============================] - 0s 234us/sample - loss: 92025.5703 - mse: 92025.5703 - mae: 200.6151\n",
      "Epoch 76/200\n",
      "51/51 [==============================] - 0s 260us/sample - loss: 92023.5000 - mse: 92023.5000 - mae: 202.0835\n",
      "Epoch 77/200\n",
      "51/51 [==============================] - 0s 311us/sample - loss: 92020.9609 - mse: 92020.9609 - mae: 201.0378\n",
      "Epoch 78/200\n",
      "51/51 [==============================] - 0s 296us/sample - loss: 92019.1953 - mse: 92019.1953 - mae: 201.4363\n",
      "Epoch 79/200\n",
      "51/51 [==============================] - 0s 329us/sample - loss: 92018.6016 - mse: 92018.6016 - mae: 201.7037\n",
      "Epoch 80/200\n",
      "51/51 [==============================] - 0s 262us/sample - loss: 92019.0234 - mse: 92019.0234 - mae: 200.8645\n",
      "Epoch 81/200\n",
      "51/51 [==============================] - 0s 470us/sample - loss: 92019.5078 - mse: 92019.5078 - mae: 202.2001\n",
      "Epoch 82/200\n",
      "51/51 [==============================] - 0s 383us/sample - loss: 92019.5391 - mse: 92019.5391 - mae: 200.5354\n",
      "Epoch 83/200\n",
      "51/51 [==============================] - 0s 310us/sample - loss: 92018.8203 - mse: 92018.8203 - mae: 202.3417\n",
      "Epoch 84/200\n",
      "51/51 [==============================] - 0s 350us/sample - loss: 92017.4375 - mse: 92017.4375 - mae: 200.5195\n",
      "Epoch 85/200\n",
      "51/51 [==============================] - 0s 320us/sample - loss: 92015.7578 - mse: 92015.7578 - mae: 202.2111\n",
      "Epoch 86/200\n",
      "51/51 [==============================] - 0s 384us/sample - loss: 92014.1953 - mse: 92014.1953 - mae: 200.6418\n",
      "Epoch 87/200\n",
      "51/51 [==============================] - 0s 352us/sample - loss: 92013.0781 - mse: 92013.0781 - mae: 202.1112\n",
      "Epoch 88/200\n",
      "51/51 [==============================] - 0s 349us/sample - loss: 92011.8984 - mse: 92011.8984 - mae: 200.6765\n",
      "Epoch 89/200\n",
      "51/51 [==============================] - 0s 356us/sample - loss: 92010.7031 - mse: 92010.7031 - mae: 202.0530\n",
      "Epoch 90/200\n",
      "51/51 [==============================] - 0s 398us/sample - loss: 92009.6875 - mse: 92009.6875 - mae: 200.6854\n",
      "Epoch 91/200\n",
      "51/51 [==============================] - 0s 341us/sample - loss: 92008.9219 - mse: 92008.9219 - mae: 202.0945\n",
      "Epoch 92/200\n",
      "51/51 [==============================] - 0s 318us/sample - loss: 92008.7969 - mse: 92008.7969 - mae: 200.5343\n",
      "Epoch 93/200\n",
      "51/51 [==============================] - 0s 311us/sample - loss: 92010.0391 - mse: 92010.0391 - mae: 202.4379\n",
      "Epoch 94/200\n",
      "51/51 [==============================] - 0s 294us/sample - loss: 92013.9297 - mse: 92013.9297 - mae: 199.9404\n",
      "Epoch 95/200\n",
      "51/51 [==============================] - 0s 263us/sample - loss: 92021.0859 - mse: 92021.0859 - mae: 203.2711\n",
      "Epoch 96/200\n",
      "51/51 [==============================] - 0s 292us/sample - loss: 92032.6562 - mse: 92032.6562 - mae: 198.9258\n",
      "Epoch 97/200\n",
      "51/51 [==============================] - 0s 328us/sample - loss: 92040.3594 - mse: 92040.3594 - mae: 204.1278\n",
      "Epoch 98/200\n",
      "51/51 [==============================] - 0s 274us/sample - loss: 92034.2812 - mse: 92034.2812 - mae: 198.7898\n",
      "Epoch 99/200\n",
      "51/51 [==============================] - 0s 271us/sample - loss: 92012.2578 - mse: 92012.2578 - mae: 202.9934\n",
      "Epoch 100/200\n",
      "51/51 [==============================] - 0s 334us/sample - loss: 91997.5781 - mse: 91997.5781 - mae: 201.1800\n",
      "Epoch 101/200\n",
      "51/51 [==============================] - 0s 307us/sample - loss: 92003.8359 - mse: 92003.8359 - mae: 200.1684\n",
      "Epoch 102/200\n",
      "51/51 [==============================] - 0s 289us/sample - loss: 92016.9609 - mse: 92016.9609 - mae: 203.3589\n",
      "Epoch 103/200\n",
      "51/51 [==============================] - 0s 286us/sample - loss: 92016.7188 - mse: 92016.7188 - mae: 199.2931\n",
      "Epoch 104/200\n",
      "51/51 [==============================] - 0s 254us/sample - loss: 92002.2266 - mse: 92002.2266 - mae: 202.5981\n",
      "Epoch 105/200\n",
      "51/51 [==============================] - 0s 312us/sample - loss: 91992.8359 - mse: 91992.8359 - mae: 201.2867\n",
      "Epoch 106/200\n",
      "51/51 [==============================] - 0s 298us/sample - loss: 91998.2656 - mse: 91998.2656 - mae: 200.2166\n",
      "Epoch 107/200\n",
      "51/51 [==============================] - 0s 302us/sample - loss: 92005.6484 - mse: 92005.6484 - mae: 202.9902\n",
      "Epoch 108/200\n",
      "51/51 [==============================] - 0s 350us/sample - loss: 92001.9688 - mse: 92001.9688 - mae: 199.8079\n",
      "Epoch 109/200\n",
      "51/51 [==============================] - 0s 341us/sample - loss: 91992.2578 - mse: 91992.2578 - mae: 202.1030\n",
      "Epoch 110/200\n",
      "51/51 [==============================] - 0s 429us/sample - loss: 91988.1406 - mse: 91988.1406 - mae: 201.4789\n",
      "Epoch 111/200\n",
      "51/51 [==============================] - 0s 470us/sample - loss: 91992.3984 - mse: 91992.3984 - mae: 200.3148\n",
      "Epoch 112/200\n",
      "51/51 [==============================] - 0s 434us/sample - loss: 91996.7344 - mse: 91996.7344 - mae: 202.7305\n",
      "Epoch 113/200\n",
      "51/51 [==============================] - 0s 444us/sample - loss: 91994.4531 - mse: 91994.4531 - mae: 199.9881\n",
      "Epoch 114/200\n",
      "51/51 [==============================] - 0s 382us/sample - loss: 91987.3125 - mse: 91987.3125 - mae: 202.0831\n",
      "Epoch 115/200\n",
      "51/51 [==============================] - 0s 390us/sample - loss: 91983.1875 - mse: 91983.1875 - mae: 201.3186\n",
      "Epoch 116/200\n",
      "51/51 [==============================] - 0s 320us/sample - loss: 91984.8750 - mse: 91984.8750 - mae: 200.5881\n",
      "Epoch 117/200\n",
      "51/51 [==============================] - 0s 326us/sample - loss: 91988.1484 - mse: 91988.1484 - mae: 202.4389\n",
      "Epoch 118/200\n",
      "51/51 [==============================] - 0s 321us/sample - loss: 91988.2969 - mse: 91988.2969 - mae: 200.0526\n",
      "Epoch 119/200\n",
      "51/51 [==============================] - 0s 334us/sample - loss: 91984.5703 - mse: 91984.5703 - mae: 202.2893\n",
      "Epoch 120/200\n",
      "51/51 [==============================] - 0s 299us/sample - loss: 91979.6016 - mse: 91979.6016 - mae: 200.7593\n",
      "Epoch 121/200\n",
      "51/51 [==============================] - 0s 324us/sample - loss: 91977.2578 - mse: 91977.2578 - mae: 201.2034\n",
      "Epoch 122/200\n",
      "51/51 [==============================] - 0s 313us/sample - loss: 91977.8906 - mse: 91977.8906 - mae: 201.8376\n",
      "Epoch 123/200\n",
      "51/51 [==============================] - 0s 291us/sample - loss: 91979.4609 - mse: 91979.4609 - mae: 200.3602\n",
      "Epoch 124/200\n",
      "51/51 [==============================] - 0s 302us/sample - loss: 91980.4219 - mse: 91980.4219 - mae: 202.3606\n",
      "Epoch 125/200\n",
      "51/51 [==============================] - 0s 320us/sample - loss: 91975.8906 - mse: 91975.8906 - mae: 200.1678\n",
      "Epoch 126/200\n",
      "51/51 [==============================] - 0s 273us/sample - loss: 91968.6484 - mse: 91968.6484 - mae: 202.1792\n",
      "Epoch 127/200\n",
      "51/51 [==============================] - 0s 327us/sample - loss: 91963.6641 - mse: 91963.6641 - mae: 201.4527\n",
      "Epoch 128/200\n",
      "51/51 [==============================] - 0s 317us/sample - loss: 91984.7578 - mse: 91984.7578 - mae: 199.1278\n",
      "Epoch 129/200\n",
      "51/51 [==============================] - 0s 365us/sample - loss: 92255.2266 - mse: 92255.2266 - mae: 208.7133\n",
      "Epoch 130/200\n",
      "51/51 [==============================] - 0s 384us/sample - loss: 93190.8203 - mse: 93190.8203 - mae: 187.1665\n",
      "Epoch 131/200\n",
      "51/51 [==============================] - 0s 345us/sample - loss: 92639.7344 - mse: 92639.7344 - mae: 212.7232\n",
      "Epoch 132/200\n",
      "51/51 [==============================] - 0s 284us/sample - loss: 92082.6953 - mse: 92082.6953 - mae: 206.0726\n",
      "Epoch 133/200\n",
      "51/51 [==============================] - 0s 275us/sample - loss: 92820.1875 - mse: 92820.1875 - mae: 189.3043\n",
      "Epoch 134/200\n",
      "51/51 [==============================] - 0s 456us/sample - loss: 91968.6484 - mse: 91968.6484 - mae: 202.5709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      "51/51 [==============================] - 0s 322us/sample - loss: 92593.5391 - mse: 92593.5391 - mae: 212.3015\n",
      "Epoch 136/200\n",
      "51/51 [==============================] - 0s 212us/sample - loss: 92060.3203 - mse: 92060.3203 - mae: 196.8394\n",
      "Epoch 137/200\n",
      "51/51 [==============================] - 0s 288us/sample - loss: 92362.8125 - mse: 92362.8125 - mae: 192.8393\n",
      "Epoch 138/200\n",
      "51/51 [==============================] - 0s 379us/sample - loss: 92111.9688 - mse: 92111.9688 - mae: 206.6035\n",
      "Epoch 139/200\n",
      "51/51 [==============================] - 0s 242us/sample - loss: 92216.2656 - mse: 92216.2656 - mae: 208.2058\n",
      "Epoch 140/200\n",
      "51/51 [==============================] - 0s 252us/sample - loss: 92122.3594 - mse: 92122.3594 - mae: 195.6620\n",
      "Epoch 141/200\n",
      "51/51 [==============================] - 0s 381us/sample - loss: 92134.9609 - mse: 92134.9609 - mae: 195.4522\n",
      "Epoch 142/200\n",
      "51/51 [==============================] - 0s 295us/sample - loss: 92105.0391 - mse: 92105.0391 - mae: 206.4767\n",
      "Epoch 143/200\n",
      "51/51 [==============================] - 0s 245us/sample - loss: 92087.4609 - mse: 92087.4609 - mae: 206.1495\n",
      "Epoch 144/200\n",
      "51/51 [==============================] - 0s 309us/sample - loss: 92080.6016 - mse: 92080.6016 - mae: 196.4249\n",
      "Epoch 145/200\n",
      "51/51 [==============================] - 0s 297us/sample - loss: 92061.4141 - mse: 92061.4141 - mae: 196.8171\n",
      "Epoch 146/200\n",
      "51/51 [==============================] - 0s 296us/sample - loss: 92053.1953 - mse: 92053.1953 - mae: 205.4456\n",
      "Epoch 147/200\n",
      "51/51 [==============================] - 0s 404us/sample - loss: 92044.1562 - mse: 92044.1562 - mae: 205.2420\n",
      "Epoch 148/200\n",
      "51/51 [==============================] - 0s 319us/sample - loss: 92029.2188 - mse: 92029.2188 - mae: 197.5559\n",
      "Epoch 149/200\n",
      "51/51 [==============================] - 0s 320us/sample - loss: 92033.1797 - mse: 92033.1797 - mae: 197.4470\n",
      "Epoch 150/200\n",
      "51/51 [==============================] - 0s 397us/sample - loss: 92008.1016 - mse: 92008.1016 - mae: 204.3022\n",
      "Epoch 151/200\n",
      "51/51 [==============================] - 0s 334us/sample - loss: 92023.7188 - mse: 92023.7188 - mae: 204.7595\n",
      "Epoch 152/200\n",
      "51/51 [==============================] - 0s 360us/sample - loss: 91991.9219 - mse: 91991.9219 - mae: 198.6481\n",
      "Epoch 153/200\n",
      "51/51 [==============================] - 0s 284us/sample - loss: 92015.9609 - mse: 92015.9609 - mae: 197.8611\n",
      "Epoch 154/200\n",
      "51/51 [==============================] - 0s 303us/sample - loss: 91978.5703 - mse: 91978.5703 - mae: 203.2765\n",
      "Epoch 155/200\n",
      "51/51 [==============================] - 0s 370us/sample - loss: 92007.8438 - mse: 92007.8438 - mae: 204.3578\n",
      "Epoch 156/200\n",
      "51/51 [==============================] - 0s 364us/sample - loss: 91969.4766 - mse: 91969.4766 - mae: 199.5655\n",
      "Epoch 157/200\n",
      "51/51 [==============================] - 0s 280us/sample - loss: 92000.5391 - mse: 92000.5391 - mae: 198.2567\n",
      "Epoch 158/200\n",
      "51/51 [==============================] - 0s 261us/sample - loss: 91962.1562 - mse: 91962.1562 - mae: 202.4555\n",
      "Epoch 159/200\n",
      "51/51 [==============================] - 0s 256us/sample - loss: 91993.5391 - mse: 91993.5391 - mae: 203.9655\n",
      "Epoch 160/200\n",
      "51/51 [==============================] - 0s 228us/sample - loss: 91957.4219 - mse: 91957.4219 - mae: 200.2591\n",
      "Epoch 161/200\n",
      "51/51 [==============================] - 0s 270us/sample - loss: 91986.3359 - mse: 91986.3359 - mae: 198.6487\n",
      "Epoch 162/200\n",
      "51/51 [==============================] - 0s 289us/sample - loss: 91953.7266 - mse: 91953.7266 - mae: 201.8590\n",
      "Epoch 163/200\n",
      "51/51 [==============================] - 0s 298us/sample - loss: 91979.9531 - mse: 91979.9531 - mae: 203.5474\n",
      "Epoch 164/200\n",
      "51/51 [==============================] - 0s 472us/sample - loss: 91951.1875 - mse: 91951.1875 - mae: 200.7258\n",
      "Epoch 165/200\n",
      "51/51 [==============================] - 0s 311us/sample - loss: 91973.5703 - mse: 91973.5703 - mae: 199.0412\n",
      "Epoch 166/200\n",
      "51/51 [==============================] - 0s 337us/sample - loss: 91948.9141 - mse: 91948.9141 - mae: 201.4693\n",
      "Epoch 167/200\n",
      "51/51 [==============================] - 0s 268us/sample - loss: 91968.0703 - mse: 91968.0703 - mae: 203.1445\n",
      "Epoch 168/200\n",
      "51/51 [==============================] - 0s 338us/sample - loss: 91947.1250 - mse: 91947.1250 - mae: 201.0094\n",
      "Epoch 169/200\n",
      "51/51 [==============================] - 0s 321us/sample - loss: 91962.7031 - mse: 91962.7031 - mae: 199.4117\n",
      "Epoch 170/200\n",
      "51/51 [==============================] - 0s 307us/sample - loss: 91945.4531 - mse: 91945.4531 - mae: 201.2513\n",
      "Epoch 171/200\n",
      "51/51 [==============================] - 0s 326us/sample - loss: 91957.8750 - mse: 91957.8750 - mae: 202.7536\n",
      "Epoch 172/200\n",
      "51/51 [==============================] - 0s 336us/sample - loss: 91943.7422 - mse: 91943.7422 - mae: 201.1422\n",
      "Epoch 173/200\n",
      "51/51 [==============================] - 0s 377us/sample - loss: 91953.9766 - mse: 91953.9766 - mae: 199.7160\n",
      "Epoch 174/200\n",
      "51/51 [==============================] - 0s 234us/sample - loss: 91942.1016 - mse: 91942.1016 - mae: 201.1487\n",
      "Epoch 175/200\n",
      "51/51 [==============================] - 0s 269us/sample - loss: 91950.0625 - mse: 91950.0625 - mae: 202.4443\n",
      "Epoch 176/200\n",
      "51/51 [==============================] - 0s 293us/sample - loss: 91940.3984 - mse: 91940.3984 - mae: 201.1675\n",
      "Epoch 177/200\n",
      "51/51 [==============================] - 0s 321us/sample - loss: 91946.5781 - mse: 91946.5781 - mae: 199.9991\n",
      "Epoch 178/200\n",
      "51/51 [==============================] - 0s 335us/sample - loss: 91938.6953 - mse: 91938.6953 - mae: 201.1442\n",
      "Epoch 179/200\n",
      "51/51 [==============================] - 0s 330us/sample - loss: 91943.6250 - mse: 91943.6250 - mae: 202.1932\n",
      "Epoch 180/200\n",
      "51/51 [==============================] - 0s 297us/sample - loss: 91937.0000 - mse: 91937.0000 - mae: 201.1135\n",
      "Epoch 181/200\n",
      "51/51 [==============================] - 0s 331us/sample - loss: 91940.8516 - mse: 91940.8516 - mae: 200.1972\n",
      "Epoch 182/200\n",
      "51/51 [==============================] - 0s 342us/sample - loss: 91935.2656 - mse: 91935.2656 - mae: 201.1868\n",
      "Epoch 183/200\n",
      "51/51 [==============================] - 0s 285us/sample - loss: 91938.2266 - mse: 91938.2266 - mae: 201.9925\n",
      "Epoch 184/200\n",
      "51/51 [==============================] - 0s 501us/sample - loss: 91933.4766 - mse: 91933.4766 - mae: 201.0585\n",
      "Epoch 185/200\n",
      "51/51 [==============================] - 0s 329us/sample - loss: 91935.6250 - mse: 91935.6250 - mae: 200.3560\n",
      "Epoch 186/200\n",
      "51/51 [==============================] - 0s 385us/sample - loss: 91931.6172 - mse: 91931.6172 - mae: 201.2311\n",
      "Epoch 187/200\n",
      "51/51 [==============================] - 0s 394us/sample - loss: 91933.1641 - mse: 91933.1641 - mae: 201.7927\n",
      "Epoch 188/200\n",
      "51/51 [==============================] - 0s 269us/sample - loss: 91929.9609 - mse: 91929.9609 - mae: 200.9667\n",
      "Epoch 189/200\n",
      "51/51 [==============================] - 0s 309us/sample - loss: 91930.8594 - mse: 91930.8594 - mae: 200.5035\n",
      "Epoch 190/200\n",
      "51/51 [==============================] - 0s 339us/sample - loss: 91928.1406 - mse: 91928.1406 - mae: 201.3057\n",
      "Epoch 191/200\n",
      "51/51 [==============================] - 0s 299us/sample - loss: 91928.4297 - mse: 91928.4297 - mae: 201.6215\n",
      "Epoch 192/200\n",
      "51/51 [==============================] - 0s 263us/sample - loss: 91926.3906 - mse: 91926.3906 - mae: 200.8615\n",
      "Epoch 193/200\n",
      "51/51 [==============================] - 0s 259us/sample - loss: 91926.1484 - mse: 91926.1484 - mae: 200.6684\n",
      "Epoch 194/200\n",
      "51/51 [==============================] - 0s 254us/sample - loss: 91924.6250 - mse: 91924.6250 - mae: 201.3759\n",
      "Epoch 195/200\n",
      "51/51 [==============================] - 0s 310us/sample - loss: 91923.9609 - mse: 91923.9609 - mae: 201.4538\n",
      "Epoch 196/200\n",
      "51/51 [==============================] - 0s 279us/sample - loss: 91922.8125 - mse: 91922.8125 - mae: 200.7973\n",
      "Epoch 197/200\n",
      "51/51 [==============================] - 0s 267us/sample - loss: 91921.7969 - mse: 91921.7969 - mae: 200.8143\n",
      "Epoch 198/200\n",
      "51/51 [==============================] - 0s 333us/sample - loss: 91920.9297 - mse: 91920.9297 - mae: 201.3923\n",
      "Epoch 199/200\n",
      "51/51 [==============================] - 0s 323us/sample - loss: 91919.6406 - mse: 91919.6406 - mae: 201.2567\n",
      "Epoch 200/200\n",
      "51/51 [==============================] - 0s 332us/sample - loss: 91919.0391 - mse: 91919.0391 - mae: 200.7513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e511c88>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, A], y,\n",
    "          batch_size = N, \n",
    "          epochs = 200,\n",
    "          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 3ms/sample - loss: 92243.4922 - mse: 92243.4922 - mae: 202.0776\n",
      "Done.\n",
      "Test loss: 92243.4921875\n",
      "Test accuracy: 92243.4921875\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate([X, A],\n",
    "                              y,\n",
    "                              batch_size=N)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X,A],batch_size = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99914.9269742747\n"
     ]
    }
   ],
   "source": [
    "mse = np.mean((y - y_pred)**2)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 101.1037634    44.55773226   25.82899847 ...    8.76332721\n",
      "    87.24791959 -336.52356111]\n",
      " [ 158.81885129  102.27282015   83.54408636 ...   66.4784151\n",
      "   144.96300748 -278.80847322]\n",
      " [ 170.98201352  114.43598238   95.70724859 ...   78.64157733\n",
      "   157.12616971 -266.64531099]\n",
      " ...\n",
      " [ 214.39474851  157.84871737  139.11998357 ...  122.05431231\n",
      "   200.5389047  -223.23257601]\n",
      " [ 102.48668271   45.94065157   27.21191778 ...   10.14624652\n",
      "    88.6308389  -335.1406418 ]\n",
      " [ 123.01312619   66.46709505   47.73836126 ...   30.67269\n",
      "   109.15728238 -314.61419832]]\n"
     ]
    }
   ],
   "source": [
    "pred_error = y_pred-y\n",
    "print(pred_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Errors')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14e61d278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(pred_error, density=True, bins=50)\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
